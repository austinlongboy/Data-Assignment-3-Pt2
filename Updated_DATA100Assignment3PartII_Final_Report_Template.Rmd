---
title: "The Correlation Between Global Happiness, Ice Extent and Covid Cases"
subtitle: "Exploring Disparate Data: Part 3 - Final Report"
author: "data100 is my personal hell"
date: "Due November 26th, 2025"
output: 
        bookdown::pdf_document2: 
          toc: FALSE
---

List your group members, including their student numbers, here:

-   Austin Liu 169135314
-   Franco Mejia Batres 169112259
-   

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE
)
```
Abstract

This paper intends to explore the significance of a relationship between world happiness, polar ice extents and cases of COVID-19 through three compiled variables from three publicly accessible datasets. The three compiled datasets are from the World Happiness Report (happiness.parquet), ice extent by hemispherical determined compiled data over the year, compiled and averaged, (ice_extent_yearly.parquet) and COVID-19 globally totals for 2020 (covid_2020.parquet). These three variables were subsequently cleaned, merged and assessed through relative descriptive and correlational analyses to statistically assess any measure of relationship between the variables. Ultimately, significant findings yielded findings relatively weak in strength (.3-.4) to moderate (.5) holdings in some regions - although not everywhere. Thus the less happiness holds reported relative to life the more polar ice and COVID-19 cases suggesting that globally, life, climate and health have increasingly happy factors as well. Yet the fact that these findings come from a merged data point of view in a compiled effort from COVID-19 compiled findings from 2020 per country suggests this is not overly meaningful except for the fact that these environmental/epidemiological/social stressors exist, en masse, across the globe - all at once.

Introduction

21st century global stressors have plagued life in the 21st century and subsequently, impact life in the 21st century - global pandemics have risen with COVID-19 and climate change has determined a reduced polar ice extent and subsequently reduced ice extents per year (per annum) due to increased temperature determined changes over time for millions of people. Thus, social and economic life has changed across nations for billions of people in transition and simultaneously, decimal derived compiled data on ice extents have emerged over time per hemisphere based on annualized averages (increase or decrease based on temperature). Yet the third facet of this worldwide simultaneous experience is connected to a happiness report as compiled data has emerged over time linking various nations to a world's happiness score.

Thus establishing a relationship based on health-based stressors, climate-based stressors and social stressors as assessed over time internationally adds significance to the intersectional nature of how these three variables are more the same than different. This is an exploratory endeavor to take three variables from three compiled datasets which have been derived from three publicly available aggregate datasets relative to this idea. The first variable is the average cases of COVID-19 per nation based on a derived one year (2020) total. The second variable is the world's happiness score based on a life ladder indicator which compiles various assessed responses for happiness means per nation (or continental average for this exploratory study). The third variable is ice extent year or annualized averages based on hemispherical data collection.

Thus these three variables will be assessed through data cleaning, merging, visualization and correlational testing all completed within RStudio to determine any significance relative to one another. Since these are compiled efforts, causation cannot be determined beyond causal association where international borders rarely cross relative to health, climate and happiness holds as data comes from various sources.

Ultimately, limitations relative to findings will be assessed based on significances found such as an imperfect dataset temporally derived assessed through a continental basis once merged for relative findings to determine whether these findings are reasonable and valid within a reasonable range relative to research conclusions.

# Data Description

This dataset contains the variables for the World Happiness Report's developed model of national life-evaluation ("ladder") scores. Thus this dataset contains the developed score for each nation for predicted happiness, measures of statistical error (standard error and upper and lower whisker of the confidence interval), the main predictors that help explain differences in happiness at the country level (logged GDP per capita - social circumstances - social support, healthy life expectancy - health outcomes - freedom to make life choices - personal agency - generosity - prosocial behavior - and perceived corruption - institutional trust). For these four predictors, it also contains the extent to which these variables are used to help create a generalized predicted happiness score for each nation in the "Explained by" columns. Finally, it contains a baseline value for "Dystopia" (the model's reference minimum for predicted happiness) and a "Dystopia + residual" which shows how much is left from the predicted happiness score by accounting for all these explanations. In this way, the predicted happiness score for each nation can be disaggregated into component pieces that drive it.

To clean this dataset, I would start by assessing all variables for missing values and variances. For example, since the most pertinent variables come from the predictor columns and the Explains by components, I would fill in what's missing or remove cases if the missing values are too much to handle. I'd examine logged GDP per capita, social support, life expectancy, and contributions for appropriate numerical presentation - for example, if they are text instead - and decimal points for consistency. I'd also rewrite variable names for consistency (spaces to _ or unique variable designations that are aligned throughout the study) to render the dataset accessible. In addition, I would assess that each observation is not compiled per country/year for ease of coding due to no duplications. I would assess extreme values for appropriateness or typographical errors - like, is generosity ever -3 or is that a typo? - and assess patterns (if perceiving corruption is -3 across the board, that's plausible; if everyone has 102 years of life - unrealistic - then it's a typo). Finally, I'd assess relative variables for appropriateness (the total ladder score should feasibly accommodate how the other 4 Explains components pan out and the Dystopia + residual should equal how the model says it should. Once these assessments are made and corrections, if necessary, tidied up, all variables will be cleaned and suitable for appropriate modeling.

## World Happiness Report (happiness.parquet)

```{r load_data1}
happiness_clean <- happiness |>
  rename(
    country = country_name,
    score   = ladder_score
  )

happiness_clean
# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1

# Note that the code in this document will not be shown
# when you click "knit", so the placement of this code
# chunk is purely for your benefit: You can see what happened
# with your data, which makes it easier to describe below!
```

This dataset (from the National Hurricane Center) is a panel of time-series data observed by month over a period of multiple years successively. Each row represents a different time-series (station, region, variable, etc.) and each column represents a different calendar month over the years assessed (1978 through 2025). As the columns only show the months in the header relative to the year, and each column holds the monthly value for that year, this is essentially wide time-series data. At the end of each row, two summary statistics are provided - the 1981-2010 mean and the 1981-2010 median - which represent long-term climatological averages for the monthly data over the 30 year reference period for that particular row. The data seems to be continuous numbers (temperature, precipitation or similar monthly related variables) with NAs for non-essential months for earlier years. Overall this is a wide time-series panel of observed monthly data for almost 50 years with summary statistics of considerations for long-term averages.
In order to clean the data, we \<\<steps to clean the data, concise but precise enough that a reader could follow your steps without seeing your code\>\>.

## Ice extent: ice_extent_yearly.parquet

```{r load_data2}
library(dplyr)
library(readr)
library(stringr)

url_north <- "https://noaadata.apps.nsidc.org/NOAA/G02135/north/daily/data/N_seaice_extent_daily_v4.0.csv"
url_south <- "https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/data/S_seaice_extent_daily_v4.0.csv"

ice_north <- read_csv(url_north, show_col_types = FALSE) |>
  mutate(hemisphere = "north")

ice_south <- read_csv(url_south, show_col_types = FALSE) |>
  mutate(hemisphere = "south")

ice_clean <- bind_rows(ice_north, ice_south) |>
  mutate(
    Year  = as.integer(Year),
    Month = as.integer(Month),
    Day   = as.integer(Day),
    Extent = as.numeric(Extent),
    hemisphere = str_to_lower(hemisphere)
  ) |>
  group_by(hemisphere) |>
  filter(
    Year  == max(Year,  na.rm = TRUE)
  ) |>
  filter(
    Month == max(Month, na.rm = TRUE)
  ) |>
  filter(
    Day   == max(Day,   na.rm = TRUE)
  ) |>
  ungroup()

ice_clean
# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1

# Reminder: do NOT print your data to the screen unless it's
# completely necessary
```

The dataset is an extensive, daily, country-level, time-series of COVID-19 case, testing and vaccination and socio-demographic variables. Therefore, each entry relates to a specific country over a specific day relative to an ISO code and continent; geographical location and temporal extent. Within the dataset, daily, temporal epidemiological variables of interest to this project include totals confirmed cases, new confirmed cases, totals deaths and new deaths, smoothed deaths and cases, deaths per million and cases per million and smoothed deaths and cases per million. The health systems variables of interest are ICU patients, hospital patients and weekly admissions calculated relative to a reproduced rate. The testing totals variables include total tests administered, new tests smoothed total tests, positivity rate and tests per case. The vaccination rollouts variables include total vaccinations, numbers vaccinated, numbers fully vaccinated, number of booster doses, new vaccinations, vaccinations per one hundred or one million. A stringency index is included to relate how stringent public policy has been relative to a government-based approach to COVID-19 over time. In addition, countries are associated with various socio-demographic variables - population size and density, age structure (0-14; 65+), GDP per capita, poverty measures, prevalence measures relative to health systems response - beds per 1,000 residents at 4 different time intervals - expected years life at birth and human development index - sexed age structure extrapolates excess mortality measures. Thus, this dataset links dynamic, time-restricted measures of the pandemic with more stable measures (unlikely to change from day to day - and within the day - and daily measures not likely to change) as well as stable demographic measures per country for an all-encompassing, extensive study of COVID-19 trends.

In order to clean the data, we \<\<steps to clean the data, concise but precise enough that a reader could follow your steps without seeing your code\>\>

## Covid 2020 Cases: covid_2020.parquet

```{r load_data3}
library(dplyr)
library(tidyr)
library(stringr)
library(arrow)

covid_2020 <- read.csv("owid-covid-data.csv")
covid_2020
covid_19 <-covid_2020 |>
  rename(
    country = location,
    year    = date
  ) |>
  filter(
    !country %in% c(
      "Africa", "Asia", "Europe", "North America", "South America",
      "Oceania", "European Union")) |>
  group_by(country) |>
  slice_max(order_by = year, n = 1, with_ties = FALSE) |>
  ungroup()

covid_19

# Put in your code to load in the data set, along with any
# necessary cleaning beyond what was done in Part 1
```

The data come from \<<place>\> and detail \<<more specific description of the data>\>.

In order to clean the data, we \<\<steps to clean the data, concise but precise enough that a reader could follow your steps without seeing your code\>\>

## Combining the Data

Explain how any combinations of data were performed. Explain what kind of join was needed, whether columns had to be modified (for example, matching "country" names.)

# Exploratory Data Analysis

To achieve our goals, we explored the data by...

We explored many aspects of the data, but will demonstrate three. These are \<\<insight 1\>\>, \<\<insight 2\>\>, and \<<insight3>\>

The first aspect that we found interesting is shown in Figure \@ref(fig:insight1). The insight should be specific to the data shown, not a general statement beyond the data (leave that for the conclusion).

```{r insight1, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items.", fig.pos="H"}
# This is an example of how you can control figures and captions in
# an R chunk. Note that you can reference figures using:
# \@ref(fig:insight1), where "insight1" is the label of this code
# chunk (the first bit of text after the "r" in "```{r label, options...}")
```

This insight is supported by the summary statistics in Table \@ref(tab:summary_stats)

```{r summary_stats, tab.cap= " "}
# Calculate the relevant summary statistics here.
# Note that the "kable" function in the "knitr" package
# is convenient for making nice tables. Other packages can
# do much fancier things with tables, but keep in mind that
# the insights should be the star, not the formatting.
```

The next insight that we found is shown in Figure \@ref(fig:insight2).

```{r insight2, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items.", fig.pos="H"}
# This figure will have a height of 4 and a width of 6.
# Feel free to change this, and to apply different sizes
# to the other figures you create.
```

Finally, Figure \@ref(fig:insight3) shows ...

```{r insight3, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
```

# Conclusion and Future Work - Franco

Overall, we found \<<general ideas>\>.

A second paragraph about our findings.

The next steps in this analysis are...

The limitations of this analysis are as follows. (Do not simply list potential issues with sampling, but relate them to your analysis and how they affect your conclusions. An honest and complete acknowledgement of the limitations makes the analysis more trustworthy.)

# References

I am not strict about MLA or APA style or anything like that. For this report, I would much rather have your citations be easy to match to your insights.

The easiest way is to use Rmd's [footnote](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html#inline-formatting) syntax. This will put a number beside the word where the footnote appears, and the full text of the footnote at the bottom of the page (pdf) or end of the document (html). The syntax is:[^1], where I suggest that you put in something like this [^2] to make references for this assignment.

[^1]: See the source view to see this footnote

[^2]: The relevance to the insight is ... . From \<<name of source and name of article>\>, published on \<<date>\>, url: \<<link to page>\>

Alternatively, you could make a list of citations with their main arguments and why they're relevent to your insights, methods, etc.

The link above also references "bibtex" files. These are also extremely convenient, but have a steep learning curve and they make it difficult to tie them to an insight. If you use bibtext, then make sure that you provide a sentence to describe the source and it's relevance when you cite it - don't just add citations to the end of a sentence (this is common practice in academia, but I want to know that your citations are directly relevant for this assignmnet).

https://arctic.noaa.gov/report-card/report-card-2023/sea-ice-2023/
https://covid.ourworldindata.org/data/owid-covid-data.csv
https://worldhappiness.report/ed/2023/#appendices-and-data




